{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdannels/movie_recommender/blob/main/final_movie_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oknvqvvI63k4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa9bc62-57e1-447c-bf6c-d1eccafa34b6"
      },
      "source": [
        "%%capture\n",
        "!pip install fuzzywuzzy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPNqNtnMxVge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde1e23b-af60-47cf-8b62-519f3b54e447"
      },
      "source": [
        "%%capture\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from fuzzywuzzy import process\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import string\n",
        "import gensim\n",
        "\n",
        "\n",
        "#df = pd.read_csv(\"C:/Users/samda/Documents/Statistics/Fall_2021/Computing/Computing_project/IMDB-Movie-Data.csv\",\n",
        "#                 header = 0, index_col = 0)\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/sdannels/movie_recommender/main/IMDB-Movie-Data.csv', header = 0, index_col = 0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq1XTcPMxdGN"
      },
      "source": [
        "# function to score movies based on presence of same actors\n",
        "def get_actors(df, title):\n",
        "    # get string of actor names from given title\n",
        "    given_actors = df.loc[df['Title'] == title, 'Actors'].iloc[0]\n",
        "    # get actor strings from all other movies in data\n",
        "    compare_actors = df.loc[df['Title'] != title, 'Actors']\n",
        "    \n",
        "    # get top matches\n",
        "    matches = process.extract(given_actors, compare_actors, limit = len(df))\n",
        " \n",
        "    # extract score and index number\n",
        "    scores = [x[1:3] for x in matches]\n",
        "    \n",
        "    # convert to dataframe\n",
        "    scores_df = pd.DataFrame(scores, columns = ['actor_score', 'Rank'])\n",
        "    # normalize score to (0-1)\n",
        "    scores_df['actor_score'] = (scores_df['actor_score']-min(scores_df['actor_score']))/(max(scores_df['actor_score']) - min(scores_df['actor_score']))\n",
        "    \n",
        "    # merge scores into given dataframe\n",
        "    out = pd.merge(df, scores_df, how = 'left', left_on = df.index, right_on = 'Rank')\n",
        "    out.drop('Rank', axis = 1, inplace = True)\n",
        "\n",
        "    return(out)\n",
        "    \n",
        "#actor_matches = get_actors(df, 'Guardians of the Galaxy')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haXsLRVlxivm"
      },
      "source": [
        "# function to score movies based on same genres\n",
        "def get_genres(df, title):\n",
        "    # get string of genres from given title\n",
        "    given_genres = df.loc[df['Title'] == title, 'Genre'].iloc[0]\n",
        "    # get genre strings from all other movies in data\n",
        "    compare_genres = df.loc[df['Title'] != title, 'Genre']\n",
        "    \n",
        "    # get top matches\n",
        "    matches = process.extract(given_genres, compare_genres, limit = len(df))\n",
        " \n",
        "    # extract score and index number\n",
        "    scores = [x[1:3] for x in matches]\n",
        "    \n",
        "    # convert to dataframe\n",
        "    scores_df = pd.DataFrame(scores, columns = ['genre_score', 'Rank'])\n",
        "    # normalize score to (0-1)\n",
        "    scores_df['genre_score'] = (scores_df['genre_score']-min(scores_df['genre_score']))/(max(scores_df['genre_score']) - min(scores_df['genre_score']))\n",
        "    \n",
        "    # merge scores into given dataframe\n",
        "    out = pd.merge(df, scores_df, how = 'left', left_on = df.index, right_on = 'Rank')\n",
        "    out.drop('Rank', axis = 1, inplace = True)\n",
        "\n",
        "    return(out)\n",
        "\n",
        "#genre_matches = get_genres(df, 'Guardians of the Galaxy')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWz_WOFTxjjZ"
      },
      "source": [
        "# function to find movies directed by the same person\n",
        "def get_director(df, title):\n",
        "    # create column with director to match\n",
        "    df['given_director'] = df.loc[df['Title'] == title, 'Director'].iloc[0]\n",
        "    # 1 if match, 0 if not\n",
        "    df['director_score'] = (df['Director'] == df['given_director']).astype(int)\n",
        "    df.drop('given_director', axis = 1, inplace = True)\n",
        "    return(df)\n",
        "\n",
        "#director_match = get_director(df, 'Guardians of the Galaxy')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSTkcHhrxnFv"
      },
      "source": [
        "# function to compare IMDB ratings\n",
        "def get_IMDB(df, title):\n",
        "    # create column for given IMDB rating\n",
        "    df['given_rating'] = df.loc[df['Title'] == title, 'Rating'].iloc[0]\n",
        "    # create column with absolute value of differences in film's rating\n",
        "    df['rating_diff'] = abs(df['Rating'] - df['given_rating'])\n",
        "    # normalize to 0-1 scale\n",
        "    df['rating_diff'] = (df['rating_diff']-min(df['rating_diff']))/(max(df['rating_diff']) - min(df['rating_diff']))\n",
        "    df.drop(['given_rating'], axis = 1, inplace = True)\n",
        "    return(df)\n",
        "\n",
        "#rating_match = get_IMDB(df, 'Guardians of the Galaxy') "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITYknZP8xxKh"
      },
      "source": [
        "# function to match descriptions using tfidf and cosine similiarity\n",
        "def tfidf_matches(title, indices, cosine_sim):\n",
        "    \n",
        "        # Get the index of the movie that matches the title\n",
        "        idx = indices[title]\n",
        "\n",
        "        # Get the pairwise similarity scores of all movies with that movie\n",
        "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "        \n",
        "        # Sort the movies based on the similarity scores\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "        \n",
        "        # dataframe with results\n",
        "        out = pd.DataFrame(sim_scores, columns = ['index_value', 'desc_score'])\n",
        "\n",
        "        # Return the top 10 most similar movies\n",
        "        return(out)\n",
        "\n",
        "\n",
        "# function to get apply cosine similarity scores based on tfidf and merge scores into dataframe\n",
        "def get_description_tfidf(df, title, ngram_max = 4):\n",
        "    \n",
        "    # fill missing values\n",
        "    df['Title'] = df['Title'].fillna('')\n",
        "    \n",
        "    # TFID vectorizer for 1-5 word range, remove meaningless words (the, and, of, etc.)\n",
        "    tfidf = TfidfVectorizer(stop_words='english', ngram_range = (1,ngram_max)) \n",
        "\n",
        "    # vectorize data\n",
        "    tfidf_matrix = tfidf.fit_transform(df['Title'])\n",
        "    \n",
        "    # calculate cosine similarity\n",
        "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "    \n",
        "    # get indices\n",
        "    indices = pd.Series(df.index, index = df['Title']).drop_duplicates()\n",
        "    \n",
        "    # find matches\n",
        "    matches = tfidf_matches(title = title, indices = indices, cosine_sim = cosine_sim)\n",
        "    \n",
        "    # merge to original dataframe\n",
        "    df = pd.merge(df, matches, how = 'left', left_on = df.index, right_on = 'index_value')\n",
        "\n",
        "    # normalize score to (0-1)\n",
        "    df['desc_score'] = (df['desc_score']-min(df['desc_score']))/(max(df['desc_score']) - min(df['desc_score']))\n",
        "    \n",
        "    # clean up dataframe\n",
        "    df.loc[df['Title'] == title, 'desc_score'] = np.nan\n",
        "    df.drop(['index_value'], axis = 1, inplace = True)\n",
        "    \n",
        "    return(df)\n",
        "\n",
        "#test = get_description(df = df, title = 'Bridesmaids')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo7oicgGx29H"
      },
      "source": [
        "# load google news pretrained model\n",
        "wv = gensim.models.KeyedVectors.load_word2vec_format(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", binary=True)  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz7ERFvZx7Hx"
      },
      "source": [
        "# function to match description with word2vec\n",
        "def get_description_word2vec(df, title):\n",
        "   \n",
        "    # create copy of original dataframe\n",
        "    df2 = df.copy()\n",
        "    \n",
        "    # get column number of Description\n",
        "    col_num = df.columns.get_loc(\"Description\")\n",
        "    \n",
        "    # convert description to lower case string and tokenize\n",
        "    df2['Description'] = df2['Description'].str.lower()\n",
        "    df2['Description'] = df2['Description'].apply(word_tokenize)\n",
        "    \n",
        "    # strip description of stop words\n",
        "    list_stopwords = set(stopwords.words('english') + list(punctuation))\n",
        "    df2['Description'] = df2['Description'].apply(lambda x: [word for word in x if word not in list_stopwords])\n",
        "    df2['Description'] = df2['Description'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\n",
        "    df2['Description'] = df2['Description'].apply(lambda x : [word for word in x if len(word) > 0])\n",
        "    df2['Description'] = df2['Description'].apply(lambda x : list(set(x)))\n",
        "    \n",
        "    # create matrix vocabulary\n",
        "    matrix_vocab = []\n",
        "    titles = []\n",
        "    for list_ in df2.to_numpy():\n",
        "        list_[col_num] = [word for word in list_[col_num] if word in wv.vocab]\n",
        "        matrix_vocab.append(list_[col_num])\n",
        "        titles.append(list_[0])\n",
        "    \n",
        "    # get description for given title\n",
        "    matrix_title_vocab = [word for word in df2[df2['Title'] == title].to_numpy()[0,col_num] if word in wv.vocab]\n",
        "    matrix_similarity = []\n",
        "    desc_string = []\n",
        "    \n",
        "    # compare description to all other descriptions using cosine similarity\n",
        "    for list1 in matrix_vocab:\n",
        "        score_desc = wv.n_similarity(list1, matrix_title_vocab)\n",
        "        desc_string.append(list1)\n",
        "        matrix_similarity.append(score_desc)\n",
        "        \n",
        "    # adjust similarity dataframe to merge\n",
        "    df_similarity = pd.DataFrame([titles, desc_string, matrix_similarity])\n",
        "    df_similarity = df_similarity.T\n",
        "    df_similarity.columns = ['Title', 'Description', 'desc_score']\n",
        "    \n",
        "    # merge description score to original dataframe\n",
        "    out = pd.merge(df2, df_similarity, on = 'Title', suffixes = ('', '_y'), how = 'left')\n",
        "    out.drop(['Description_y'], axis = 1, inplace = True)\n",
        "    out['desc_score'] = out['desc_score'].astype(float)\n",
        "    out.loc[out['Title'] == title, 'desc_score'] = np.nan\n",
        "    out = out.drop_duplicates(subset = ['Title', 'Actors'])\n",
        "\n",
        "    # normalize score to (0-1)\n",
        "    out['desc_score'] = (out['desc_score']-min(out['desc_score']))/(max(out['desc_score']) - min(out['desc_score']))\n",
        "    \n",
        "    return(out)\n",
        "    \n",
        "#test = get_description_word2vec(df, 'How to Train Your Dragon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW8umqycyGO1"
      },
      "source": [
        "def get_recommendations(title, df = df, weights = (.3, .1, .25, .05, .3), top_n = 5, word2vec = True, kids = True):\n",
        "    \n",
        "    '''\n",
        "    This function generates movie recommendations based on Actors, Director, and Description.\n",
        "    The recommendation equation is defined using the given weights as follows:\n",
        "       Score = w0*Actors + w1*Director + w2*Genres - w3*IMDB + w4*Description\n",
        "       \n",
        "    title : Title of movie entered as string\n",
        "    df: dataframe with movies\n",
        "    weights: vector of weights\n",
        "        0 - Actors\n",
        "        1 - Director\n",
        "        2 - Genres\n",
        "        3 - IMDB Rating\n",
        "        4 - Description\n",
        "    top_n: how many recommendations to make (list top n titles)\n",
        "    '''\n",
        "    \n",
        "    # get actor similiarity score\n",
        "    df = get_actors(df = df, title = title)\n",
        "    \n",
        "    # get director score\n",
        "    df = get_director(df = df, title = title)\n",
        "    \n",
        "    # get genre score\n",
        "    df = get_genres(df = df, title = title)\n",
        "    \n",
        "    # compare ratings\n",
        "    df = get_IMDB(df = df, title = title)\n",
        "    \n",
        "    # get description score\n",
        "    if word2vec == True:\n",
        "        df = get_description_word2vec(df = df, title = title)\n",
        "    else:\n",
        "        df = get_description_tfidf(df = df, title = title)\n",
        "    \n",
        "    # calculate recommendation score\n",
        "    df['recommendation_score'] = weights[0]*df['actor_score'] \\\n",
        "    + weights[1]*df['director_score'] + weights[2]*df['genre_score'] \\\n",
        "    - weights[3]*df['rating_diff'] + weights[4]*df['desc_score']\n",
        "\n",
        "    # stop it from recommending \"Sausage Party\" to children\n",
        "    if kids == True:\n",
        "      df.loc[df['Title'] == 'Sausage Party', 'recommendation_score'] = 0\n",
        "    \n",
        "    # get movie recommendation list\n",
        "    recommendations = df.sort_values('recommendation_score', ascending = False)\n",
        "    recommendation_list = recommendations['Title'].head(top_n)\n",
        "    \n",
        "    return(recommendation_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1A2aU86xN38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343fe5da-3544-48e3-c462-752b26974c79"
      },
      "source": [
        "# weights = (Actors, Director, Genre, IMDB Rating, Description)\n",
        "get_recommendations(title = \"The Dark Knight\", weights = (.2, .1, .35, .05, .3), top_n = 5, word2vec=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124    The Dark Knight Rises\n",
              "512                  Shooter\n",
              "791                  Hancock\n",
              "518                  Chappie\n",
              "313             The Babadook\n",
              "Name: Title, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}